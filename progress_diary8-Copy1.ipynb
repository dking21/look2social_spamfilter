{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.language_processing2 import processing_text\n",
    "from src.language_processing2 import vectorize_text\n",
    "from src.language_processing2 import vectorize_desc\n",
    "from src.modeling import test_model\n",
    "from src.modeling import test_model2\n",
    "from src.modeling import test_model3\n",
    "from src.modeling import test_model4\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model6(data,column,TFIDF_column,estimators,dep):\n",
    "    data2 = data.sample(frac=1)\n",
    "    data2_training = data2[:16000]\n",
    "    data2_testing = data2[16000:]\n",
    "    y = data2_training[column]\n",
    "    X = data2_training[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none'] + TFIDF_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    model = GradientBoostingClassifier(subsample=0.5, learning_rate=0.1, n_estimators=estimators,max_depth=dep)\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    ll_performance = []\n",
    "    auc_performance = []\n",
    "    acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        log_ll = log_loss(y_test, y_pred)\n",
    "        ll_performance.append(log_ll)\n",
    "        auc = roc_auc_score(y_test,y_predict)\n",
    "        auc_performance.append(auc)\n",
    "        acc = accuracy_score(y_test,y_predict)\n",
    "        acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\" + \"Score summary for initial test (first 80% of data)\" + \"\\n\")\n",
    "    print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "    print(np.mean(acc_performance))\n",
    "    print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "    print(np.mean(ll_performance))\n",
    "    print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "    print(np.mean(auc_performance))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    y = data2_testing[column]\n",
    "    X = data2_testing[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none'] + TFIDF_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    #model = model()\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    ll_performance = []\n",
    "    auc_performance = []\n",
    "    acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        log_ll = log_loss(y_test, y_pred)\n",
    "        ll_performance.append(log_ll)\n",
    "        auc = roc_auc_score(y_test,y_predict)\n",
    "        auc_performance.append(auc)\n",
    "        acc = accuracy_score(y_test,y_predict)\n",
    "        acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\" + \"Score summary for final test (last 20% of data)\" + \"\\n\")\n",
    "    print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "    print(np.mean(acc_performance))\n",
    "    print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "    print(np.mean(ll_performance))\n",
    "    print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "    print(np.mean(auc_performance))\n",
    "    #print(\"\\n\" + \"Coefficients of this model are\" + \"\\n\")\n",
    "    #print(model.coef_)\n",
    "    #print(\"\\n\" + \"Most effective predictor was\" + \"\\n\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_candidate = range(300,900,200)\n",
    "depth_candidate = range(2,8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator is 300\n",
      " depth is 2\n",
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.952\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12719035478532043\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6819651544482398\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9455839178582881\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.15125087219433717\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6248348297018851\n",
      "estimator is 500\n",
      " depth is 2\n",
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9531875000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12665184178680847\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6937526685332067\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9478304862064564\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.15632027320031647\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6827370131896009\n",
      "estimator is 700\n",
      " depth is 2\n",
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9535\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12640898021845165\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.7104834707694301\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.943082991646975\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.16910955140631106\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6529715076925943\n",
      "estimator is 300\n",
      " depth is 4\n",
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.954375\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12330974603041919\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.700550026917514\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9473329784153848\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1566831707780362\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6586420751334477\n",
      "estimator is 500\n",
      " depth is 4\n",
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9535625\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12713302089146364\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.718086446742995\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9415876662899555\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.18816232458113516\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6202543144724553\n",
      "estimator is 700\n",
      " depth is 4\n"
     ]
    }
   ],
   "source": [
    "for d in depth_candidate:\n",
    "    for e in estimator_candidate:\n",
    "        df = pd.read_excel('testing2.xlsx')\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        processing_text(df,'text')\n",
    "        col_name_lst1 = vectorize_text(df,700)\n",
    "        processing_text(df,'description')\n",
    "        col_name_lst2 = vectorize_desc(df,700)\n",
    "        print(\"estimator is \" + str(e) + \"\\n depth is \" + str(d))\n",
    "        test_model6(df,'spam_marketing',col_name_lst1+col_name_lst2,e,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "depth_candidate = list(range(2,8,2))\n",
    "print(depth_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9541875\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12411044494842816\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6935869807570457\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9458298697700194\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.15094225130900585\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6803877176686943\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "test_model6(df,'spam_marketing',col_name_lst1+col_name_lst2,500,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62256773395a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.feature_importance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model4(data,column,TFIDF_column):\n",
    "    data2 = data.sample(frac=1)\n",
    "    data2_training = data2[:16000]\n",
    "    data2_testing = data2[16000:]\n",
    "    y = data2_training[column]\n",
    "    X = data2_training[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none'] + TFIDF_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    model = RandomForestClassifier(n_estimators=500)\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    ll_performance = []\n",
    "    auc_performance = []\n",
    "    acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        log_ll = log_loss(y_test, y_pred)\n",
    "        ll_performance.append(log_ll)\n",
    "        auc = roc_auc_score(y_test,y_predict)\n",
    "        auc_performance.append(auc)\n",
    "        acc = accuracy_score(y_test,y_predict)\n",
    "        acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\" + \"Score summary for initial test (first 80% of data)\" + \"\\n\")\n",
    "    print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "    print(np.mean(acc_performance))\n",
    "    print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "    print(np.mean(ll_performance))\n",
    "    print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "    print(np.mean(auc_performance))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    y = data2_testing[column]\n",
    "    X = data2_testing[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none'] + TFIDF_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    #model = model()\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    ll_performance = []\n",
    "    auc_performance = []\n",
    "    acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        log_ll = log_loss(y_test, y_pred)\n",
    "        ll_performance.append(log_ll)\n",
    "        auc = roc_auc_score(y_test,y_predict)\n",
    "        auc_performance.append(auc)\n",
    "        acc = accuracy_score(y_test,y_predict)\n",
    "        acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\" + \"Score summary for final test (last 20% of data)\" + \"\\n\")\n",
    "    print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "    print(np.mean(acc_performance))\n",
    "    print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "    print(np.mean(ll_performance))\n",
    "    print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "    print(np.mean(auc_performance))\n",
    "    #print(\"\\n\" + \"Coefficients of this model are\" + \"\\n\")\n",
    "    #print(model.coef_)\n",
    "    #print(\"\\n\" + \"Most effective predictor was\" + \"\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9563124999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11041367908153166\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6952529752683233\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9558152060547757\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12212558008827554\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.65464789168158\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model = test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.56645703e-03, 1.45130761e-03, 9.59920976e-04, 6.94925339e-03,\n",
       "       1.05959724e-02, 1.18035119e-02, 1.05156765e-02, 1.27527707e-02,\n",
       "       1.15527283e-02, 1.35104589e-02, 1.51078245e-02, 9.49119877e-04,\n",
       "       6.99455081e-04, 8.74897364e-05, 5.44590191e-04, 2.03124648e-03,\n",
       "       4.39128715e-05, 1.33529375e-08, 2.76992769e-05, 5.98722804e-05,\n",
       "       1.86765433e-04, 0.00000000e+00, 9.26395252e-08, 2.14038031e-08,\n",
       "       1.22886949e-03, 1.08111163e-05, 2.32860226e-04, 1.15636487e-03,\n",
       "       1.69659799e-04, 1.06611276e-05, 3.03120886e-05, 9.95236356e-07,\n",
       "       2.99884197e-05, 1.77041145e-04, 1.51435961e-09, 3.13364510e-06,\n",
       "       7.04989344e-06, 9.04059576e-06, 2.42741786e-04, 1.64483843e-03,\n",
       "       0.00000000e+00, 1.14128066e-03, 7.12930093e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.77789940e-04])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fim[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none'] + col_name_lst1+col_name_lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(fim,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8322bf933406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.94025\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1936155587980399\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.5018150223625382\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/daniel/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9405889147294062\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.18812077242576453\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.5020416379112032\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "test_model3(df,'spam_marketing',LogisticRegression,col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9492499999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1516921893055328\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6564082560931521\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9465804900981005\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1566818514874027\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6068767363139868\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model = test_model4(df,'spam_marketing',[col_name_lst1+col_name_lst2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model4_notext(data,column):\n",
    "    data2 = data.sample(frac=1)\n",
    "    data2_training = data2[:16000]\n",
    "    data2_testing = data2[16000:]\n",
    "    y = data2_training[column]\n",
    "    X = data2_training[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    model = RandomForestClassifier(n_estimators=500)\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    ll_performance = []\n",
    "    auc_performance = []\n",
    "    acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        log_ll = log_loss(y_test, y_pred)\n",
    "        ll_performance.append(log_ll)\n",
    "        auc = roc_auc_score(y_test,y_predict)\n",
    "        auc_performance.append(auc)\n",
    "        acc = accuracy_score(y_test,y_predict)\n",
    "        acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\" + \"Score summary for initial test (first 80% of data)\" + \"\\n\")\n",
    "    print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "    print(np.mean(acc_performance))\n",
    "    print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "    print(np.mean(ll_performance))\n",
    "    print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "    print(np.mean(auc_performance))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    y = data2_testing[column]\n",
    "    X = data2_testing[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    #model = model()\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    ll_performance = []\n",
    "    auc_performance = []\n",
    "    acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        log_ll = log_loss(y_test, y_pred)\n",
    "        ll_performance.append(log_ll)\n",
    "        auc = roc_auc_score(y_test,y_predict)\n",
    "        auc_performance.append(auc)\n",
    "        acc = accuracy_score(y_test,y_predict)\n",
    "        acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "    print(\"\\n\" + \"Score summary for final test (last 20% of data)\" + \"\\n\")\n",
    "    print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "    print(np.mean(acc_performance))\n",
    "    print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "    print(np.mean(ll_performance))\n",
    "    print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "    print(np.mean(auc_performance))\n",
    "    #print(\"\\n\" + \"Coefficients of this model are\" + \"\\n\")\n",
    "    #print(model.coef_)\n",
    "    #print(\"\\n\" + \"Most effective predictor was\" + \"\\n\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9489375000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1515473389897413\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6561029827990346\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9485773705561316\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1623562428468641\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6022374598849909\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "model = test_model4_notext(df,'spam_marketing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.905\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.19883826600468407\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.884958984709117\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.905392262166058\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.2046275543500637\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.883971083014124\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "model = test_model4_notext(df,'spam_hijack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.905\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.20717610307263845\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8858491910164623\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.8998997512461043\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.20798073105550513\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8770400466377197\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model = test_model4(df,'spam_hijack',[col_name_lst1+col_name_lst2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9065\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.20546445325851023\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8852625737462698\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.8844243946936652\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.22264537692690595\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8577221530201606\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,100)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,100)\n",
    "model = test_model4(df,'spam_hijack',[col_name_lst1+col_name_lst2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9998750000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.003092100597794022\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.9998955067920585\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9987521832123811\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.007662978990518721\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.9988556892816469\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model1 = test_model4(df,'spam_bot',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances1 = model1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.71309691e-02, 4.70280082e-03, 2.89095526e-03, ...,\n",
       "       3.97073531e-05, 3.45981934e-04, 3.50271232e-06])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_importances1 = np.argsort(importances1)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183,  78, 673,   3, 151,   0, 207,   4,   7,   5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_importances1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10106304354651631"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adobe sign\n",
      "Docusign\n",
      "listed_count\n",
      "favourites_count\n",
      "statuses_count\n"
     ]
    }
   ],
   "source": [
    "print(columns[3])\n",
    "print(columns[0])\n",
    "print(columns[4])\n",
    "print(columns[7])\n",
    "print(columns[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9978125\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.00730198551077333\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.9871231088396126\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.997254055871557\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.017310543475745167\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.9834503099253504\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model2 = test_model4(df,'spam_corporate',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6  903 1358 1147  759 1350 1002    8  749 1051]\n"
     ]
    }
   ],
   "source": [
    "importances2 = model2.feature_importances_\n",
    "ordered_importances2 = np.argsort(importances2)[::-1]\n",
    "print(ordered_importances2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "followers_count\n",
      "friends_count\n"
     ]
    }
   ],
   "source": [
    "print(columns[6])\n",
    "print(columns[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9315\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1491869620161151\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.9198086426345913\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9078807351160176\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.17335343793716218\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.904031525897957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model3 = test_model4(df,'spam_hijack',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[673  78   3 207 183 151   0   5   7   6]\n"
     ]
    }
   ],
   "source": [
    "importances3 = model3.feature_importances_\n",
    "ordered_importances3 = np.argsort(importances3)[::-1]\n",
    "print(ordered_importances3[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adobe sign\n",
      "Docusign\n",
      "statuses_count\n",
      "favourites_count\n",
      "followers_count\n"
     ]
    }
   ],
   "source": [
    "print(columns[3])\n",
    "print(columns[0])\n",
    "print(columns[5])\n",
    "print(columns[7])\n",
    "print(columns[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9570000000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11444542820988637\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.696277571427081\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9505758076718316\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.13040259286901446\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6282588926768036\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "model4 = test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10   9   5   6   4   7 673  78   8 207]\n"
     ]
    }
   ],
   "source": [
    "importances4 = model4.feature_importances_\n",
    "ordered_importances4 = np.argsort(importances4)[::-1]\n",
    "print(ordered_importances4[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_float_cos\n",
      "time_float_sin\n",
      "statuses_count\n",
      "followers_count\n",
      "listed_count\n",
      "favourites_count\n",
      "friends_count\n"
     ]
    }
   ],
   "source": [
    "print(columns[10])\n",
    "print(columns[9])\n",
    "print(columns[5])\n",
    "print(columns[6])\n",
    "print(columns[4])\n",
    "print(columns[7])\n",
    "print(columns[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
