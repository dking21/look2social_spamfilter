{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.language_processing2 import processing_text\n",
    "from src.language_processing2 import vectorize_text\n",
    "from src.language_processing2 import vectorize_desc\n",
    "from src.modeling import test_model\n",
    "from src.modeling import test_model2\n",
    "from src.modeling import test_model3\n",
    "from src.modeling import test_model4\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_marketing</th>\n",
       "      <th>spam_hijack</th>\n",
       "      <th>spam_corporate</th>\n",
       "      <th>spam_bot</th>\n",
       "      <th>spam_known</th>\n",
       "      <th>spam_own</th>\n",
       "      <th>Docusign</th>\n",
       "      <th>onespan</th>\n",
       "      <th>...</th>\n",
       "      <th>desc-TF-IDF-990</th>\n",
       "      <th>desc-TF-IDF-991</th>\n",
       "      <th>desc-TF-IDF-992</th>\n",
       "      <th>desc-TF-IDF-993</th>\n",
       "      <th>desc-TF-IDF-994</th>\n",
       "      <th>desc-TF-IDF-995</th>\n",
       "      <th>desc-TF-IDF-996</th>\n",
       "      <th>desc-TF-IDF-997</th>\n",
       "      <th>desc-TF-IDF-998</th>\n",
       "      <th>desc-TF-IDF-999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just closed a deal in 27 hours using #AdobeSig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just closed a deal in 2 days using #AdobeSign ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just closed a deal in 2 hours using #AdobeSign...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>just closed a deal in 26 hours using #AdobeSig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just closed a deal in 6 days using #AdobeSign ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  spam_marketing  \\\n",
       "0  just closed a deal in 27 hours using #AdobeSig...     0               0   \n",
       "1  just closed a deal in 2 days using #AdobeSign ...     0               0   \n",
       "2  just closed a deal in 2 hours using #AdobeSign...     0               0   \n",
       "3  just closed a deal in 26 hours using #AdobeSig...     0               0   \n",
       "4  just closed a deal in 6 days using #AdobeSign ...     0               0   \n",
       "\n",
       "   spam_hijack  spam_corporate  spam_bot  spam_known  spam_own  Docusign  \\\n",
       "0            0               0         1           0         0     False   \n",
       "1            0               0         1           0         0     False   \n",
       "2            0               0         1           0         0     False   \n",
       "3            0               0         1           0         0     False   \n",
       "4            0               0         1           0         0     False   \n",
       "\n",
       "   onespan  ...  desc-TF-IDF-990  desc-TF-IDF-991  desc-TF-IDF-992  \\\n",
       "0    False  ...              0.0              0.0              0.0   \n",
       "1    False  ...              0.0              0.0              0.0   \n",
       "2    False  ...              0.0              0.0              0.0   \n",
       "3    False  ...              0.0              0.0              0.0   \n",
       "4    False  ...              0.0              0.0              0.0   \n",
       "\n",
       "  desc-TF-IDF-993  desc-TF-IDF-994  desc-TF-IDF-995  desc-TF-IDF-996  \\\n",
       "0             0.0              0.0              0.0              0.0   \n",
       "1             0.0              0.0              0.0              0.0   \n",
       "2             0.0              0.0              0.0              0.0   \n",
       "3             0.0              0.0              0.0              0.0   \n",
       "4             0.0              0.0              0.0              0.0   \n",
       "\n",
       "   desc-TF-IDF-997  desc-TF-IDF-998  desc-TF-IDF-999  \n",
       "0              0.0              0.0              0.0  \n",
       "1              0.0              0.0              0.0  \n",
       "2              0.0              0.0              0.0  \n",
       "3              0.0              0.0              0.0  \n",
       "4              0.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 2022 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9201875000000002\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.25771578635491316\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8878695993945074\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9156244843571472\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.23974509975605765\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8888592257717483\n"
     ]
    }
   ],
   "source": [
    "test_model3(df,'spam_hijack',RandomForestClassifier,col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9498749999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.15445423847246337\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6554110814259806\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9448323635356054\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.17843372977557242\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.5799872220837077\n"
     ]
    }
   ],
   "source": [
    "df2 = df.sample(frac=1)\n",
    "df2_training = df2[:16000]\n",
    "df2_testing = df2[16000:]\n",
    "y = df2_training['spam_marketing']\n",
    "X = df2_training[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "model = RandomForestClassifier(n_estimators=250)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "ll_performance = []\n",
    "auc_performance = []\n",
    "acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    log_ll = log_loss(y_test, y_pred)\n",
    "    ll_performance.append(log_ll)\n",
    "    auc = roc_auc_score(y_test,y_predict)\n",
    "    auc_performance.append(auc)\n",
    "    acc = accuracy_score(y_test,y_predict)\n",
    "    acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "print(\"\\n\" + \"Score summary for initial test (first 80% of data)\" + \"\\n\")\n",
    "print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "print(np.mean(acc_performance))\n",
    "print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "print(np.mean(ll_performance))\n",
    "print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "print(np.mean(auc_performance))\n",
    "print(\"\\n\")\n",
    "\n",
    "y = df2_testing['spam_marketing']\n",
    "X = df2_testing[['Docusign', 'onespan', 'signnow','adobe sign','listed_count', 'statuses_count','followers_count','favourites_count', 'friends_count','time_float_sin','time_float_cos', 'is_description_none']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    #model = model()\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "ll_performance = []\n",
    "auc_performance = []\n",
    "acc_performance = []\n",
    "#kfold split on X_ (which is X_train of len 110)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    log_ll = log_loss(y_test, y_pred)\n",
    "    ll_performance.append(log_ll)\n",
    "    auc = roc_auc_score(y_test,y_predict)\n",
    "    auc_performance.append(auc)\n",
    "    acc = accuracy_score(y_test,y_predict)\n",
    "    acc_performance.append(acc)\n",
    "        \n",
    "        \n",
    "print(\"\\n\" + \"Score summary for final test (last 20% of data)\" + \"\\n\")\n",
    "print(\"\\n\" + \"Accuracy score of this model is\" + \"\\n\")\n",
    "print(np.mean(acc_performance))\n",
    "print(\"\\n\" + \"Log-Loss score of this model is\" + \"\\n\")\n",
    "print(np.mean(ll_performance))\n",
    "print(\"\\n\" + \"AUC score of this model is\" + \"\\n\")\n",
    "print(np.mean(auc_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9240625\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1556343672603409\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.910441740540489\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9128776062341026\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.17532805421687905\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.8962391739257205\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,100)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,100)\n",
    "test_model4(df,'spam_hijack',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9533124999999998\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11938267802021005\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6662708871387519\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9465811127611682\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1378216713403046\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6075824549934437\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,50)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,50)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9523125\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11767705027034567\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6663946515578629\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9503220724717544\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1253113924678683\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6035565456658238\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,100)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,100)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9544374999999998\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11012634459995127\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6901226647829589\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9530670826055958\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11253423351080276\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6239737509484506\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,200)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,200)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9572499999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.10964808363758236\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.7028968225348204\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.95281832871006\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1333245138155526\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6341426617931134\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,300)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,300)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9556250000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11645599384305452\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6955077721780709\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9583108396300137\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11846880936157482\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6342123916589818\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,500)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,500)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9560625\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11534667553598912\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6906234734825025\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9553180095952379\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12011291379198488\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6499188784162111\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,700)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,700)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9584999999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.106989599102345\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6998544718954424\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9470773752261044\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.13768616072681797\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.631400157122868\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,800)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,800)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9566250000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11927033054210238\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6945236159589906\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9555698768061122\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1254935648403675\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6451012199577858\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,1000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,1000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9570624999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.10531826178893973\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6923168101650614\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9500748752338879\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12830144448145822\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6273866424361378\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,2000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,1000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.955875\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11426385733827857\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6977616236084914\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9515736252377793\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12368892743877087\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6291551757113043\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,1000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,2000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9578749999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.10821673114173773\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.7037926113725805\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9500720732500832\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1321088562327118\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6315221541210816\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,2000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,2000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.958\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11015041798686931\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6963508690491242\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9503267424447619\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.13143805894453783\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6411372088577394\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,3000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,2000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9567499999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11941480718359825\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6906272861704869\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9505776756610347\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12354345730597116\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6323403621732464\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,2000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,3000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9579374999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11194482903300354\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.700034479689825\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9505742510141625\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1413341921910043\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.619154548023811\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,3000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,3000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9563750000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.10888142393933811\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6991485538069215\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9523195755928532\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12946088931375027\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.5976114271609482\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,4000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,3000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9563124999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11780373235295535\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6927245563698061\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9518226904648491\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12466953900829361\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6128748593817976\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,3000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,4000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9570000000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.10993216614789499\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6958403033288428\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9480779947758569\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.13841091722215978\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6128184910300932\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,4000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,4000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'desc-TF-IDF-915'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'desc-TF-IDF-915'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-acd7cfe459b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcol_name_lst1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprocessing_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcol_name_lst2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_model4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'spam_marketing'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_name_lst1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol_name_lst2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/look2social_spamfilter/src/language_processing2.py\u001b[0m in \u001b[0;36mvectorize_desc\u001b[0;34m(target_df, max_feature_number)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc_tfidf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcol_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'desc-TF-IDF-{n}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtarget_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc_tfidf_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mcol_name_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol_name_lst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3445\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3446\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3448\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     def reindex_axis(self, new_index, axis, method=None, limit=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 1899\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   1900\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   3144\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3146\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3148\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,5000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,4000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,4000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,5000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9567499999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11553369705850762\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6895808656089613\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.947330487763114\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1373477982510662\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6336540909167466\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,5000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,5000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,6000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,5000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,5000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,6000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9572499999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11425174293262566\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6973548485450924\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9498264326698859\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.12321365281611592\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6051245671585574\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,6000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,6000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,7000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,6000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,6000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,7000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9569375000000001\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11460957651030898\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6888547974079732\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9478292408803212\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.14488685372547305\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6209239975307546\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,7000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,7000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score summary for initial test (first 80% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9570624999999999\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.11812024392888434\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6915929767009258\n",
      "\n",
      "\n",
      "\n",
      "Score summary for final test (last 20% of data)\n",
      "\n",
      "\n",
      "Accuracy score of this model is\n",
      "\n",
      "0.9463270662295571\n",
      "\n",
      "Log-Loss score of this model is\n",
      "\n",
      "0.1424789466251267\n",
      "\n",
      "AUC score of this model is\n",
      "\n",
      "0.6010916837343231\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,8000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,8000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,9000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,9000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('testing2.xlsx')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "processing_text(df,'text')\n",
    "col_name_lst1 = vectorize_text(df,10000)\n",
    "processing_text(df,'description')\n",
    "col_name_lst2 = vectorize_desc(df,10000)\n",
    "test_model4(df,'spam_marketing',col_name_lst1+col_name_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
